{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Softmax Regression:\n"
      ],
      "metadata": {
        "id": "-jNeU03tpRwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load Titanic dataset\n",
        "data = pd.read_csv('Titanic-Dataset.csv')\n",
        "\n",
        "# Prepare features (X) and target labels (y)\n",
        "X = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
        "y = data['Survived']\n",
        "\n",
        "# Handle missing values\n",
        "X['Age'].fillna(X['Age'].median(), inplace=True)\n",
        "X['Fare'].fillna(X['Fare'].median(), inplace=True)\n",
        "\n",
        "# Encode 'Sex' column\n",
        "X['Sex'] = X['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = X.values\n",
        "y = y.values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LOa9TXGYpu_M",
        "outputId": "68917a36-3e1d-40f2-9d97-8609b3dde52e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-f4b6cd15a3b5>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X['Age'].fillna(X['Age'].median(), inplace=True)\n",
            "<ipython-input-41-f4b6cd15a3b5>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Age'].fillna(X['Age'].median(), inplace=True)\n",
            "<ipython-input-41-f4b6cd15a3b5>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X['Fare'].fillna(X['Fare'].median(), inplace=True)\n",
            "<ipython-input-41-f4b6cd15a3b5>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Fare'].fillna(X['Fare'].median(), inplace=True)\n",
            "<ipython-input-41-f4b6cd15a3b5>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Sex'] = X['Sex'].map({'male': 0, 'female': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize features\n",
        "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
        "X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "g2kMzjEtsajz"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax function:"
      ],
      "metadata": {
        "id": "dVET2bRpspXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "    max_z = np.max(z, axis=1).reshape(-1, 1)  # Reshape (n_samples,) to (n_samples, 1)\n",
        "    exp_z = np.exp(z - max_z)  # Subtract max for numerical stability\n",
        "    sum_exp_z = np.sum(exp_z, axis=1).reshape(-1, 1)  # Reshape for element-wise division\n",
        "    return exp_z / sum_exp_z  # Normalize\n"
      ],
      "metadata": {
        "id": "TSHHmU09ssNV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross entropy loss Function:\n"
      ],
      "metadata": {
        "id": "G1Db7KBDst5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    # Small value added to avoid log(0), which is undefined\n",
        "    epsilon = 1e-15\n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip predictions to prevent log(0)\n",
        "\n",
        "    # Calculate the cross-entropy loss\n",
        "    loss = -np.mean(np.sum(y_true * np.log(y_pred), axis=1))  # Summing over class labels and averaging\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "ayThR5-VsxLj"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent"
      ],
      "metadata": {
        "id": "Szv2odUnsyz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y_onehot, w, b, learning_rate, n_iterations, tolerance=1e-5):\n",
        "    m = X.shape[0]\n",
        "    prev_loss = float('inf')\n",
        "    for i in range(n_iterations):\n",
        "        # Compute predictions\n",
        "        z = np.dot(X, w) + b\n",
        "        y_pred = softmax(z)\n",
        "\n",
        "        # Compute gradients\n",
        "        grad_w = np.dot(X.T, (y_pred - y_onehot)) / m\n",
        "        grad_b = np.sum(y_pred - y_onehot, axis=0) / m\n",
        "\n",
        "        # Update weights and bias\n",
        "        w -= learning_rate * grad_w\n",
        "        b -= learning_rate * grad_b\n",
        "\n",
        "        # Compute loss\n",
        "        loss = cross_entropy_loss(y_onehot, y_pred)\n",
        "        if abs(prev_loss - loss) < tolerance:\n",
        "            print(f\"Converged at iteration {i}: Loss = {loss:.4f}\")\n",
        "            break\n",
        "        prev_loss = loss\n",
        "\n",
        "        if i % 100 == 0 or i == n_iterations - 1:\n",
        "            print(f\"Iteration {i}: Loss = {loss:.4f}\")\n",
        "\n",
        "    return w, b\n"
      ],
      "metadata": {
        "id": "YDNPl4F1s3B1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix"
      ],
      "metadata": {
        "id": "TheOBt9LL8uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_matrix(y_true, y_pred, n_classes):\n",
        "    cm = np.zeros((n_classes, n_classes), dtype=int)\n",
        "    for true, pred in zip(y_true, y_pred):\n",
        "        cm[true, pred] += 1\n",
        "    return cm\n"
      ],
      "metadata": {
        "id": "0_Y9JtREL9e0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision"
      ],
      "metadata": {
        "id": "b1O7mrCyMGze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def precision(conf_matrix):\n",
        "    # Extract true positives (diagonal elements)\n",
        "    TP = np.diag(conf_matrix)\n",
        "    # Extract false positives (sum of each column minus the diagonal)\n",
        "    FP = np.sum(conf_matrix, axis=0) - TP\n",
        "\n",
        "    # Avoid division by zero\n",
        "    precision_values = TP / (TP + FP)\n",
        "\n",
        "    return precision_values\n"
      ],
      "metadata": {
        "id": "Tt0csRNJMHLp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall"
      ],
      "metadata": {
        "id": "AsrxCOyGMPDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def recall(conf_matrix):\n",
        "    # Extract true positives (diagonal elements)\n",
        "    TP = np.diag(conf_matrix)\n",
        "    # Extract false negatives (sum of each row minus the diagonal)\n",
        "    FN = np.sum(conf_matrix, axis=1) - TP\n",
        "\n",
        "    # Avoid division by zero\n",
        "    recall_values = TP / (TP + FN)\n",
        "\n",
        "    return recall_values\n"
      ],
      "metadata": {
        "id": "UQt3QzJUMPU3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1- Score"
      ],
      "metadata": {
        "id": "2Cs0edtDMUs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def f1_score(precision_values, recall_values):\n",
        "    # Calculate the F1 score for each class\n",
        "    f1_values = 2 * (precision_values * recall_values) / (precision_values + recall_values)\n",
        "\n",
        "    # Replace NaN values with 0 (for cases where precision + recall = 0)\n",
        "    f1_values = np.nan_to_num(f1_values)\n",
        "\n",
        "    return f1_values\n"
      ],
      "metadata": {
        "id": "8xaNDWvWMU_l"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "kIUURYbCs4tL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode y_train\n",
        "n_classes = len(np.unique(y_train))\n",
        "y_onehot = np.zeros((y_train.shape[0], n_classes))\n",
        "y_onehot[np.arange(y_train.shape[0]), y_train] = 1\n",
        "\n",
        "# Initialize weights and bias\n",
        "n_features = X_train.shape[1]\n",
        "w = np.random.randn(n_features, n_classes)\n",
        "b = np.zeros(n_classes)\n",
        "\n",
        "# Train model\n",
        "learning_rate = 0.1\n",
        "n_iterations = 1000\n",
        "w, b = gradient_descent(X_train, y_onehot, w, b, learning_rate, n_iterations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNgzcIHJs8U2",
        "outputId": "3de6f725-70e4-495e-9c12-5f770c7f13ba"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Loss = 1.0930\n",
            "Iteration 100: Loss = 0.4625\n",
            "Iteration 200: Loss = 0.4520\n",
            "Converged at iteration 268: Loss = 0.4507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict and accuracy:"
      ],
      "metadata": {
        "id": "1FFASCQTI1Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, w, b):\n",
        "    z = np.dot(X, w) + b\n",
        "    y_prob = softmax(z)\n",
        "    return np.argmax(y_prob, axis=1)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = predict(X_test, w, b)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, n_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Compute metrics for each class\n",
        "precision_score = precision(cm)\n",
        "recall_score = recall(cm)\n",
        "f1_score_value = f1_score(precision_score, recall_score)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Precision: {precision_score}\")\n",
        "print(f\"Recall: {recall_score}\")\n",
        "print(f\"F1-Score: {f1_score_value}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v14EcBfhI332",
        "outputId": "b43ee007-7af9-460c-e444-dd91861b509d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8045\n",
            "Confusion Matrix:\n",
            "[[93 12]\n",
            " [23 51]]\n",
            "Precision: [0.80172414 0.80952381]\n",
            "Recall: [0.88571429 0.68918919]\n",
            "F1-Score: [0.84162896 0.74452555]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization of confusion matrix"
      ],
      "metadata": {
        "id": "youdd3r1labU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Confusion Matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred, n_classes)\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "# Display the confusion matrix as an image\n",
        "ax.imshow(cm, cmap='Blues')\n",
        "\n",
        "# Remove grid lines\n",
        "ax.grid(False)\n",
        "\n",
        "# Set x-axis tick labels\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
        "\n",
        "# Set y-axis tick labels\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
        "\n",
        "# Set y-axis limits\n",
        "ax.set_ylim(1.5, -0.5)\n",
        "\n",
        "# Display the values in the confusion matrix\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "VHWvpj86lart",
        "outputId": "680a77d9-4a3e-4b44-e581-d4808e6ee948"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}