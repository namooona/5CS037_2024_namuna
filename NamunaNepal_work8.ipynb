{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+tM5G+jxC57NS/VWlXE44"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["1. Implement Classification Models:"],"metadata":{"id":"1Jk_zeFfqVns"}},{"cell_type":"markdown","source":["Importing necessary libraries"],"metadata":{"id":"lDxtqWUJuhii"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n","from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n","from sklearn.metrics import classification_report, f1_score, mean_squared_error, r2_score"],"metadata":{"id":"yJ1v1suTqWQ-","executionInfo":{"status":"ok","timestamp":1738426885465,"user_tz":-345,"elapsed":20,"user":{"displayName":"Namuna Nepal","userId":"14430923077148942995"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["load the dataset from sklearn"],"metadata":{"id":"2j2OLv3eu1ZV"}},{"cell_type":"code","source":["# Load the wine dataset\n","data = load_wine()\n","\n","# Convert to pandas DataFrame\n","df = pd.DataFrame(data.data, columns=data.feature_names)\n","\n","# Add the target column\n","df['target'] = data.target\n","\n","# Display the first ten rows\n","print(df.head(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"xgzul9liu0Gv","executionInfo":{"status":"ok","timestamp":1738426885466,"user_tz":-345,"elapsed":17,"user":{"displayName":"Namuna Nepal","userId":"14430923077148942995"}},"outputId":"d014e34c-3cf8-4885-943a-b3bd4846fc22"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n","0    14.23        1.71  2.43               15.6      127.0           2.80   \n","1    13.20        1.78  2.14               11.2      100.0           2.65   \n","2    13.16        2.36  2.67               18.6      101.0           2.80   \n","3    14.37        1.95  2.50               16.8      113.0           3.85   \n","4    13.24        2.59  2.87               21.0      118.0           2.80   \n","5    14.20        1.76  2.45               15.2      112.0           3.27   \n","6    14.39        1.87  2.45               14.6       96.0           2.50   \n","7    14.06        2.15  2.61               17.6      121.0           2.60   \n","8    14.83        1.64  2.17               14.0       97.0           2.80   \n","9    13.86        1.35  2.27               16.0       98.0           2.98   \n","\n","   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n","0        3.06                  0.28             2.29             5.64  1.04   \n","1        2.76                  0.26             1.28             4.38  1.05   \n","2        3.24                  0.30             2.81             5.68  1.03   \n","3        3.49                  0.24             2.18             7.80  0.86   \n","4        2.69                  0.39             1.82             4.32  1.04   \n","5        3.39                  0.34             1.97             6.75  1.05   \n","6        2.52                  0.30             1.98             5.25  1.02   \n","7        2.51                  0.31             1.25             5.05  1.06   \n","8        2.98                  0.29             1.98             5.20  1.08   \n","9        3.15                  0.22             1.85             7.22  1.01   \n","\n","   od280/od315_of_diluted_wines  proline  target  \n","0                          3.92   1065.0       0  \n","1                          3.40   1050.0       0  \n","2                          3.17   1185.0       0  \n","3                          3.45   1480.0       0  \n","4                          2.93    735.0       0  \n","5                          2.85   1450.0       0  \n","6                          3.58   1290.0       0  \n","7                          3.58   1295.0       0  \n","8                          2.85   1045.0       0  \n","9                          3.55   1045.0       0  \n"]}]},{"cell_type":"markdown","source":["Define features and use train-test-split from sklearn"],"metadata":{"id":"OlvQ6i5-yKVz"}},{"cell_type":"code","source":["# Define X and y\n","X = df.drop(columns=['target'])\n","y = df['target']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"],"metadata":{"id":"Xi9A-Iawyexb","executionInfo":{"status":"ok","timestamp":1738426885467,"user_tz":-345,"elapsed":14,"user":{"displayName":"Namuna Nepal","userId":"14430923077148942995"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Train Decision Tree Classifier\n","dt_clf = DecisionTreeClassifier(random_state=42)\n","dt_clf.fit(X_train, y_train)\n","y_pred_dt = dt_clf.predict(X_test)\n","\n","# Train Random Forest Classifier\n","rf_clf = RandomForestClassifier(random_state=42)\n","rf_clf.fit(X_train, y_train)\n","y_pred_rf = rf_clf.predict(X_test)\n","\n","# Evaluate and compare models based on F1 score\n","f1_dt = f1_score(y_test, y_pred_dt, average='weighted')\n","f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n","\n","print(f\"F1 Score (Decision Tree): {f1_dt:.4f}\")\n","print(f\"F1 Score (Random Forest): {f1_rf:.4f}\")\n","\n","# Determine the better model\n","if f1_rf > f1_dt:\n","    print(\"Random Forest Classifier performs better.\")\n","else:\n","    print(\"Decision Tree Classifier performs better.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2fDUYgJugAk","executionInfo":{"status":"ok","timestamp":1738426885947,"user_tz":-345,"elapsed":492,"user":{"displayName":"Namuna Nepal","userId":"14430923077148942995"}},"outputId":"bf51d2a7-613f-43d2-c7d7-4ad98493a579"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score (Decision Tree): 0.9628\n","F1 Score (Random Forest): 1.0000\n","Random Forest Classifier performs better.\n"]}]},{"cell_type":"markdown","source":["Hyperparameter tuning:"],"metadata":{"id":"9aiKr6OR5cbe"}},{"cell_type":"code","source":["# Define parameter grid for Random Forest Classifier\n","param_grid = {\n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","}\n","\n","# Perform GridSearchCV\n","grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),param_grid=param_grid,cv=5,scoring='f1_weighted', verbose=1, n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Best hyperparameters and evaluation\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","print(\"\\nBest Hyperparameters for Random Forest Classifier:\", best_params)\n","print(\"\\nBest F1 Score for Random Forest Classifier:\", best_score)\n","\n","# Evaluate the best model on the test set\n","best_rf = grid_search.best_estimator_\n","y_pred = best_rf.predict(X_test)\n","print(classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-JJjozN-GAp","executionInfo":{"status":"ok","timestamp":1738426920565,"user_tz":-345,"elapsed":34626,"user":{"displayName":"Namuna Nepal","userId":"14430923077148942995"}},"outputId":"a55cb828-6e28-4c06-e7b0-9b8956c0b4aa"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 36 candidates, totalling 180 fits\n","\n","Best Hyperparameters for Random Forest Classifier: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n","\n","Best F1 Score for Random Forest Classifier: 0.9680809081527346\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        19\n","           1       1.00      1.00      1.00        21\n","           2       1.00      1.00      1.00        14\n","\n","    accuracy                           1.00        54\n","   macro avg       1.00      1.00      1.00        54\n","weighted avg       1.00      1.00      1.00        54\n","\n"]}]},{"cell_type":"markdown","source":["Implememt regression model"],"metadata":{"id":"ZQkid-hzBLFH"}},{"cell_type":"code","source":[" # Using the alcohol feature as the target for regression\n","y_reg = df['alcohol']\n","X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.3, random_state=42)\n","\n","# Train Decision Tree Regressor\n","dt_regressor = DecisionTreeRegressor(random_state=42)\n","dt_regressor.fit(X_train_reg, y_train_reg)\n","dt_reg_predictions = dt_regressor.predict(X_test_reg)\n","\n","# Train a Random Forest Regressor\n","rf_regressor = RandomForestRegressor(random_state=42)\n","rf_regressor.fit(X_train_reg, y_train_reg)\n","rf_reg_predictions = rf_regressor.predict(X_test_reg)\n","\n","# Evaluate Regression Models\n","dt_mse = mean_squared_error(y_test_reg, dt_reg_predictions)\n","rf_mse = mean_squared_error(y_test_reg, rf_reg_predictions)\n","dt_r2 = r2_score(y_test_reg, dt_reg_predictions)\n","rf_r2 = r2_score(y_test_reg, rf_reg_predictions)\n","\n","print(\"Decision Tree Regressor MSE:\", dt_mse)\n","print(\"Decision Tree Regressor R2 Score:\", dt_r2)\n","print(\"\\nRandom Forest Regressor MSE:\", rf_mse)\n","print(\"Random Forest Regressor R2 Score:\", rf_r2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zTr9wpOZBN4d","executionInfo":{"status":"ok","timestamp":1738426920566,"user_tz":-345,"elapsed":11,"user":{"displayName":"Namuna Nepal","userId":"14430923077148942995"}},"outputId":"d189a26d-e80f-4390-c087-a5eb7b069e08"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Decision Tree Regressor MSE: 0.0017592592592592462\n","Decision Tree Regressor R2 Score: 0.9967228563711633\n","\n","Random Forest Regressor MSE: 0.0013293277777777996\n","Random Forest Regressor R2 Score: 0.9975237316304281\n"]}]},{"cell_type":"markdown","source":[" Identify three parameters for Random Forest Regression and Perform hyperparameter tuning using RandomSearchCV to optimize these parameters."],"metadata":{"id":"i2JhV81nT5CI"}},{"cell_type":"code","source":["# Hyperparameter Tuning for Random Forest Regressor\n","param_distributions = {\n","    'n_estimators': [50, 100, 200, 300],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Perform RandomizedSearchCV\n","random_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42), param_distributions=param_distributions,\n","                                   n_iter=50,\n","                                   cv=5,\n","                                   scoring='neg_mean_squared_error',\n","                                   verbose=1,\n","                                   n_jobs=-1,\n","                                   random_state=42)\n","random_search.fit(X_train_reg, y_train_reg)\n","\n","# Best hyperparameters\n","best_params_reg = random_search.best_params_\n","print(\"\\nBest Hyperparameters for Random Forest Regressor:\", best_params_reg)\n","\n","# model evaluation\n","best_rf_regressor = random_search.best_estimator_\n","optimized_reg_predictions = best_rf_regressor.predict(X_test_reg)\n","\n","optimized_mse = mean_squared_error(y_test_reg, optimized_reg_predictions)\n","optimized_r2 = r2_score(y_test_reg, optimized_reg_predictions)\n","\n","print(\"Optimized Random Forest Regressor MSE:\", optimized_mse)\n","print(\"Optimized Random Forest Regressor R2 Score:\", optimized_r2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Atd6ScjT6Id","executionInfo":{"status":"ok","timestamp":1738426883916,"user_tz":-345,"elapsed":62800,"user":{"displayName":"Namuna Nepal","userId":"14430923077148942995"}},"outputId":"d3a0a286-9f5c-4d79-d0d6-79a45b3cee8b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 50 candidates, totalling 250 fits\n","\n","Best Hyperparameters for Random Forest Regressor: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 30}\n","Optimized Random Forest Regressor MSE: 0.0013222566871488896\n","Optimized Random Forest Regressor R2 Score: 0.9975369036398869\n"]}]}]}